## 从TCP、UDP、 TLS协议的内部工作原理讲解优化应用， 然后是无限和移动网络的工作机制
## HTTP协议的底层细节， 讲解浏览器的新的能力
+ HTTP2.0的诸多改进
+ XHR的新特性和新功能
+ 通过SSE发送数据流
+ 通过webSocket实现双向通信
+ 通过webRTC实现端到端的音频和视频通信
+ 通过DataChannel实现端到端的数据交换

* 高性能应用：必须了解每一位数据是如何交付的， 必须理解每一种传输机制和相关协议的特点
* 等待网络，是应用最大的性能瓶颈， 再怎么优化渲染js也抵不上网络优化。


#### 首先，V8引擎： js从解释型-->编译型
+ 高效的流式传输
+ 双向实时通信
+ 交付自定义协议
+ 端到端视频会议
+ 两端之间直接的数据交换

WPO（web performance optimization）性能优化： 网站越快， 用户的粘性、忠诚度、转化率就越高
### 延迟和带宽： 大多数网站的性能瓶颈都是延迟
+ 延迟： 分组从信息源发送到目的地所需的时间（消息message和分组packet从起点到终点经历的时间）
  - 传播延迟： 消息从发送端到接收端需要的时间
  - 传输延迟： 把消息中的所有比特转移到链路中需要的时间
  - 处理延迟： 路由检查处理首部， 检查位错误及确定分组目标所需的时间
  - 排队延迟： 到来的分组排队等待处理的时间
    如果分组到达的速度超过了理由的处理能力， 那么分组就要进入入站缓冲区排队
    光缆中的每一跳， 都会涉及寻路、处理、排队和传输延迟

* 缓冲区爆满： 排队延迟影响网络整体性能的一个形象说法
* 延迟的最后一公里： 接入互联网， 本地ISP需要在附近安装多个路由收集信号， 然后再将信号转发到本地的路由节点。 链接类型， 路由技术， 部署方法五花八门， 分组传输中的这前几跳往往要花数十毫秒才能到达ISP的主路由器。
* 最后一公里的延迟与提供商、部署方法、网络拓补、甚至一天中的哪个时段都有很大关系

+ 带宽： 逻辑或物理通信路劲最大的吞吐量
  - 一条光纤的总带宽： 每个信道（波长）的数据传输速率乘以可复用的信道数。
  - 网络核心的带宽： 每秒几百太比特
  - 网络边缘的带宽： 小得多。 很大程度取决于部署技术
    用户可用带宽取决于客户端与目标服务器间最低容量连接。
  - 由于请求密度， 硬件故障， 网络攻击， 以及其他原因， 网络中的某个之间节点随时可能发生拥塞。吞吐量和延迟波动

+ 目标： 高带宽，低延迟 （多路传输，减少往返，cnd部署等等）

### TCP、UDP
#### 因特网的两个核心协议：
+ IP： 负责互联网主机之间的路由选择和寻址
+ TCP（Transmission Conntrol Protocol）：传输控制协议， 负责在不可靠的传输信道上提供可靠的抽象层。向应用隐藏了大多数网络通信的复杂细节， 比如丢包重发、按序发送、拥塞控制及避免、数据完整等等
+ UDP： 用户数据报协议。

##### 三从握手： 所有的TCP连接一开始都要经过三次握手
客户端和服务器在交换应用数据之前， 必须就起始分组序列号， 以及其他一些连接相关的细节达成一致。 处于安全考虑， 序列号由两端随机生成。
+ SYN：客户端选择一个随机序列号x， 并发送一个SYN分组，其中可能还包括其他的TCP标志和选项
+ SYN ACK： 服务器给x加1， 并选择自己的一个随机序列号y，追加自己的标志和选项，然年后返回响应。
+ ACK： 客户端给x和y加1并发送握手期间的最后一个ACK分组

客户端可以在发送ACK分组之后立即发送数据， 而服务器必须等接收到ACK分组之后才能发送数据。


